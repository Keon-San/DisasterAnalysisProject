{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optimize\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs, L1RegWeight):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        torch.cuda.empty_cache()\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            batches = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                batches += 1\n",
    "                print(\"Batch \" + str(batches))\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    if (phase != 'val' and L1RegWeight != 0):\n",
    "                        loss += L1RegWeight * (sum(p.abs().sum() for p in model.parameters()))\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.detach().item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data).detach()\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doValidation(model, dataloader):\n",
    "    results = {\"real\": [], \"pred\": []}\n",
    "    model.eval()\n",
    "    torch.set_grad_enabled(False)\n",
    "    for inputs, labels in dataloader:\n",
    "        for x in labels.tolist():\n",
    "            results['real'].append(x)\n",
    "        inputs = inputs.to(device)\n",
    "        output = model(inputs)\n",
    "        for x in torch.argmax(output, dim=1).tolist():\n",
    "            results[\"pred\"].append(x)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initModel(num_classes, batchNormalization):\n",
    "    if batchNormalization:\n",
    "        model_ft = models.vgg16_bn(pretrained=True)\n",
    "    else:\n",
    "        model_ft = models.vgg16(pretrained=True)\n",
    "    num_ftrs = model_ft.classifier[6].in_features\n",
    "    model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "    return model_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelTest = initModel(3, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "lr = 0.001\n",
    "momentum = 0.9\n",
    "regL2_mult = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optim = optimize.SGD(modelTest.parameters(), lr=lr, momentum=momentum, weight_decay=regL2_mult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.RandomCrop(224),\n",
    "        transforms.ToTensor()\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize([224, 224]),\n",
    "        transforms.ToTensor()\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DisastersDatasets(Dataset):\n",
    "    def __init__(self, csv, root_dir, transform=None):\n",
    "        self.csv = pd.read_csv(csv, delim_whitespace=True, header=None, usecols=[0,1], names=[\"img\",\"lbl\"])\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.csv)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.root_dir, self.csv[\"img\"][idx])\n",
    "\n",
    "        image = io.imread(img_name)\n",
    "        image = Image.fromarray(image)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = self.csv[\"lbl\"][idx]\n",
    "\n",
    "        if (image.shape[0] == 4):\n",
    "            image = image[0:3]\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSet = DisastersDatasets(\"ASONAM17_Damage_Image_Dataset\\\\ruby.train\", \"ASONAM17_Damage_Image_Dataset\", data_transforms['train'])\n",
    "testSet = DisastersDatasets(\"ASONAM17_Damage_Image_Dataset\\\\ruby.test\", \"ASONAM17_Damage_Image_Dataset\", data_transforms['val'])\n",
    "devSet = DisastersDatasets(\"ASONAM17_Damage_Image_Dataset\\\\ruby.dev\", \"ASONAM17_Damage_Image_Dataset\", data_transforms['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'DataLoader' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-3e7f87d60cd5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_dataloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainSet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m14\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest_dataloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestSet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m14\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdev_dataloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevSet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m14\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DataLoader' is not defined"
     ]
    }
   ],
   "source": [
    "train_dataloader = DataLoader(trainSet, batch_size = 14, shuffle=True)\n",
    "test_dataloader = DataLoader(testSet, batch_size = 14, shuffle=True)\n",
    "dev_dataloader = DataLoader(devSet, batch_size = 14, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "modelTest.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 0/2\n",
      "----------\n",
      "Batch 1\n",
      "Batch 2\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 392.00 MiB (GPU 0; 6.00 GiB total capacity; 3.96 GiB already allocated; 130.50 MiB free; 4.37 GiB reserved in total by PyTorch)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-abd18ce95912>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodelTest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodelTest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"train\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"val\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-21-a424d1ae44ed>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, dataloaders, criterion, optimizer, num_epochs, L1RegWeight)\u001b[0m\n\u001b[0;32m     47\u001b[0m                     \u001b[1;31m# backward + optimize only if in training phase\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m                         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m                         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 245\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 392.00 MiB (GPU 0; 6.00 GiB total capacity; 3.96 GiB already allocated; 130.50 MiB free; 4.37 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "modelTest, history = train_model(modelTest, {\"train\": train_dataloader, \"val\": test_dataloader}, criterion, optim, 3, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 0/2\n",
      "----------\n",
      "Batch 1\n",
      "Batch 2\n",
      "Batch 3\n",
      "Batch 4\n",
      "Batch 5\n",
      "Batch 6\n",
      "Batch 7\n",
      "Batch 8\n",
      "Batch 9\n",
      "Batch 10\n",
      "Batch 11\n",
      "Batch 12\n",
      "Batch 13\n",
      "Batch 14\n",
      "Batch 15\n",
      "Batch 16\n",
      "Batch 17\n",
      "Batch 18\n",
      "Batch 19\n",
      "Batch 20\n",
      "Batch 21\n",
      "Batch 22\n",
      "Batch 23\n",
      "Batch 24\n",
      "Batch 25\n",
      "Batch 26\n",
      "Batch 27\n",
      "Batch 28\n",
      "Batch 29\n",
      "Batch 30\n",
      "Batch 31\n",
      "Batch 32\n",
      "Batch 33\n",
      "Batch 34\n",
      "Batch 35\n",
      "Batch 36\n",
      "Batch 37\n",
      "Batch 38\n",
      "Batch 39\n",
      "Batch 40\n",
      "Batch 41\n",
      "Batch 42\n",
      "Batch 43\n",
      "Batch 44\n",
      "Batch 45\n",
      "Batch 46\n",
      "Batch 47\n",
      "Batch 48\n",
      "Batch 49\n",
      "Batch 50\n",
      "Batch 51\n",
      "Batch 52\n",
      "Batch 53\n",
      "Batch 54\n",
      "Batch 55\n",
      "Batch 56\n",
      "Batch 57\n",
      "Batch 58\n",
      "Batch 59\n",
      "Batch 60\n",
      "Batch 61\n",
      "Batch 62\n",
      "Batch 63\n",
      "Batch 64\n",
      "Batch 65\n",
      "Batch 66\n",
      "Batch 67\n",
      "Batch 68\n",
      "Batch 69\n",
      "Batch 70\n",
      "Batch 71\n",
      "Batch 72\n",
      "Batch 73\n",
      "Batch 74\n",
      "Batch 75\n",
      "Batch 76\n",
      "Batch 77\n",
      "Batch 78\n",
      "Batch 79\n",
      "Batch 80\n",
      "Batch 81\n",
      "Batch 82\n",
      "Batch 83\n",
      "Batch 84\n",
      "Batch 85\n",
      "Batch 86\n",
      "Batch 87\n",
      "Batch 88\n",
      "Batch 89\n",
      "Batch 90\n",
      "Batch 91\n",
      "Batch 92\n",
      "Batch 93\n",
      "Batch 94\n",
      "Batch 95\n",
      "Batch 96\n",
      "Batch 97\n",
      "Batch 98\n",
      "train Loss: 0.2047 Acc: 0.9291\n",
      "Batch 1\n",
      "Batch 2\n",
      "Batch 3\n",
      "Batch 4\n",
      "Batch 5\n",
      "Batch 6\n",
      "Batch 7\n",
      "Batch 8\n",
      "Batch 9\n",
      "Batch 10\n",
      "Batch 11\n",
      "Batch 12\n",
      "Batch 13\n",
      "Batch 14\n",
      "Batch 15\n",
      "Batch 16\n",
      "Batch 17\n",
      "Batch 18\n",
      "Batch 19\n",
      "Batch 20\n",
      "Batch 21\n",
      "Batch 22\n",
      "Batch 23\n",
      "Batch 24\n",
      "Batch 25\n",
      "Batch 26\n",
      "Batch 27\n",
      "Batch 28\n",
      "Batch 29\n",
      "Batch 30\n",
      "Batch 31\n",
      "Batch 32\n",
      "Batch 33\n",
      "val Loss: 0.3548 Acc: 0.8816\n",
      "Epoch 1/2\n",
      "----------\n",
      "Batch 1\n",
      "Batch 2\n",
      "Batch 3\n",
      "Batch 4\n",
      "Batch 5\n",
      "Batch 6\n",
      "Batch 7\n",
      "Batch 8\n",
      "Batch 9\n",
      "Batch 10\n",
      "Batch 11\n",
      "Batch 12\n",
      "Batch 13\n",
      "Batch 14\n",
      "Batch 15\n",
      "Batch 16\n",
      "Batch 17\n",
      "Batch 18\n",
      "Batch 19\n",
      "Batch 20\n",
      "Batch 21\n",
      "Batch 22\n",
      "Batch 23\n",
      "Batch 24\n",
      "Batch 25\n",
      "Batch 26\n",
      "Batch 27\n",
      "Batch 28\n",
      "Batch 29\n",
      "Batch 30\n",
      "Batch 31\n",
      "Batch 32\n",
      "Batch 33\n",
      "Batch 34\n",
      "Batch 35\n",
      "Batch 36\n",
      "Batch 37\n",
      "Batch 38\n",
      "Batch 39\n",
      "Batch 40\n",
      "Batch 41\n",
      "Batch 42\n",
      "Batch 43\n",
      "Batch 44\n",
      "Batch 45\n",
      "Batch 46\n",
      "Batch 47\n",
      "Batch 48\n",
      "Batch 49\n",
      "Batch 50\n",
      "Batch 51\n",
      "Batch 52\n",
      "Batch 53\n",
      "Batch 54\n",
      "Batch 55\n",
      "Batch 56\n",
      "Batch 57\n",
      "Batch 58\n",
      "Batch 59\n",
      "Batch 60\n",
      "Batch 61\n",
      "Batch 62\n",
      "Batch 63\n",
      "Batch 64\n",
      "Batch 65\n",
      "Batch 66\n",
      "Batch 67\n",
      "Batch 68\n",
      "Batch 69\n",
      "Batch 70\n",
      "Batch 71\n",
      "Batch 72\n",
      "Batch 73\n",
      "Batch 74\n",
      "Batch 75\n",
      "Batch 76\n",
      "Batch 77\n",
      "Batch 78\n",
      "Batch 79\n",
      "Batch 80\n",
      "Batch 81\n",
      "Batch 82\n",
      "Batch 83\n",
      "Batch 84\n",
      "Batch 85\n",
      "Batch 86\n",
      "Batch 87\n",
      "Batch 88\n",
      "Batch 89\n",
      "Batch 90\n",
      "Batch 91\n",
      "Batch 92\n",
      "Batch 93\n",
      "Batch 94\n",
      "Batch 95\n",
      "Batch 96\n",
      "Batch 97\n",
      "Batch 98\n",
      "train Loss: 0.1995 Acc: 0.9247\n",
      "Batch 1\n",
      "Batch 2\n",
      "Batch 3\n",
      "Batch 4\n",
      "Batch 5\n",
      "Batch 6\n",
      "Batch 7\n",
      "Batch 8\n",
      "Batch 9\n",
      "Batch 10\n",
      "Batch 11\n",
      "Batch 12\n",
      "Batch 13\n",
      "Batch 14\n",
      "Batch 15\n",
      "Batch 16\n",
      "Batch 17\n",
      "Batch 18\n",
      "Batch 19\n",
      "Batch 20\n",
      "Batch 21\n",
      "Batch 22\n",
      "Batch 23\n",
      "Batch 24\n",
      "Batch 25\n",
      "Batch 26\n",
      "Batch 27\n",
      "Batch 28\n",
      "Batch 29\n",
      "Batch 30\n",
      "Batch 31\n",
      "Batch 32\n",
      "Batch 33\n",
      "val Loss: 0.3417 Acc: 0.8882\n",
      "Epoch 2/2\n",
      "----------\n",
      "Batch 1\n",
      "Batch 2\n",
      "Batch 3\n",
      "Batch 4\n",
      "Batch 5\n",
      "Batch 6\n",
      "Batch 7\n",
      "Batch 8\n",
      "Batch 9\n",
      "Batch 10\n",
      "Batch 11\n",
      "Batch 12\n",
      "Batch 13\n",
      "Batch 14\n",
      "Batch 15\n",
      "Batch 16\n",
      "Batch 17\n",
      "Batch 18\n",
      "Batch 19\n",
      "Batch 20\n",
      "Batch 21\n",
      "Batch 22\n",
      "Batch 23\n",
      "Batch 24\n",
      "Batch 25\n",
      "Batch 26\n",
      "Batch 27\n",
      "Batch 28\n",
      "Batch 29\n",
      "Batch 30\n",
      "Batch 31\n",
      "Batch 32\n",
      "Batch 33\n",
      "Batch 34\n",
      "Batch 35\n",
      "Batch 36\n",
      "Batch 37\n",
      "Batch 38\n",
      "Batch 39\n",
      "Batch 40\n",
      "Batch 41\n",
      "Batch 42\n",
      "Batch 43\n",
      "Batch 44\n",
      "Batch 45\n",
      "Batch 46\n",
      "Batch 47\n",
      "Batch 48\n",
      "Batch 49\n",
      "Batch 50\n",
      "Batch 51\n",
      "Batch 52\n",
      "Batch 53\n",
      "Batch 54\n",
      "Batch 55\n",
      "Batch 56\n",
      "Batch 57\n",
      "Batch 58\n",
      "Batch 59\n",
      "Batch 60\n",
      "Batch 61\n",
      "Batch 62\n",
      "Batch 63\n",
      "Batch 64\n",
      "Batch 65\n",
      "Batch 66\n",
      "Batch 67\n",
      "Batch 68\n",
      "Batch 69\n",
      "Batch 70\n",
      "Batch 71\n",
      "Batch 72\n",
      "Batch 73\n",
      "Batch 74\n",
      "Batch 75\n",
      "Batch 76\n",
      "Batch 77\n",
      "Batch 78\n",
      "Batch 79\n",
      "Batch 80\n",
      "Batch 81\n",
      "Batch 82\n",
      "Batch 83\n",
      "Batch 84\n",
      "Batch 85\n",
      "Batch 86\n",
      "Batch 87\n",
      "Batch 88\n",
      "Batch 89\n",
      "Batch 90\n",
      "Batch 91\n",
      "Batch 92\n",
      "Batch 93\n",
      "Batch 94\n",
      "Batch 95\n",
      "Batch 96\n",
      "Batch 97\n",
      "Batch 98\n",
      "train Loss: 0.1898 Acc: 0.9320\n",
      "Batch 1\n",
      "Batch 2\n",
      "Batch 3\n",
      "Batch 4\n",
      "Batch 5\n",
      "Batch 6\n",
      "Batch 7\n",
      "Batch 8\n",
      "Batch 9\n",
      "Batch 10\n",
      "Batch 11\n",
      "Batch 12\n",
      "Batch 13\n",
      "Batch 14\n",
      "Batch 15\n",
      "Batch 16\n",
      "Batch 17\n",
      "Batch 18\n",
      "Batch 19\n",
      "Batch 20\n",
      "Batch 21\n",
      "Batch 22\n",
      "Batch 23\n",
      "Batch 24\n",
      "Batch 25\n",
      "Batch 26\n",
      "Batch 27\n",
      "Batch 28\n",
      "Batch 29\n",
      "Batch 30\n",
      "Batch 31\n",
      "Batch 32\n",
      "Batch 33\n",
      "val Loss: 0.3396 Acc: 0.8925\n",
      "Training complete in 3m 51s\n",
      "Best val Acc: 0.892544\n"
     ]
    }
   ],
   "source": [
    "lr = 0.0001\n",
    "optim = optim = optimize.SGD(modelTest.parameters(), lr=lr, momentum=momentum, weight_decay=regL2_mult)\n",
    "modelTest, historyTwo = train_model(modelTest, {\"train\": train_dataloader, \"val\": test_dataloader}, criterion, optim, 3, 0)\n",
    "history.append(historyTwo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 0/2\n",
      "----------\n",
      "Batch 1\n",
      "Batch 2\n",
      "Batch 3\n",
      "Batch 4\n",
      "Batch 5\n",
      "Batch 6\n",
      "Batch 7\n",
      "Batch 8\n",
      "Batch 9\n",
      "Batch 10\n",
      "Batch 11\n",
      "Batch 12\n",
      "Batch 13\n",
      "Batch 14\n",
      "Batch 15\n",
      "Batch 16\n",
      "Batch 17\n",
      "Batch 18\n",
      "Batch 19\n",
      "Batch 20\n",
      "Batch 21\n",
      "Batch 22\n",
      "Batch 23\n",
      "Batch 24\n",
      "Batch 25\n",
      "Batch 26\n",
      "Batch 27\n",
      "Batch 28\n",
      "Batch 29\n",
      "Batch 30\n",
      "Batch 31\n",
      "Batch 32\n",
      "Batch 33\n",
      "Batch 34\n",
      "Batch 35\n",
      "Batch 36\n",
      "Batch 37\n",
      "Batch 38\n",
      "Batch 39\n",
      "Batch 40\n",
      "Batch 41\n",
      "Batch 42\n",
      "Batch 43\n",
      "Batch 44\n",
      "Batch 45\n",
      "Batch 46\n",
      "Batch 47\n",
      "Batch 48\n",
      "Batch 49\n",
      "Batch 50\n",
      "Batch 51\n",
      "Batch 52\n",
      "Batch 53\n",
      "Batch 54\n",
      "Batch 55\n",
      "Batch 56\n",
      "Batch 57\n",
      "Batch 58\n",
      "Batch 59\n",
      "Batch 60\n",
      "Batch 61\n",
      "Batch 62\n",
      "Batch 63\n",
      "Batch 64\n",
      "Batch 65\n",
      "Batch 66\n",
      "Batch 67\n",
      "Batch 68\n",
      "Batch 69\n",
      "Batch 70\n",
      "Batch 71\n",
      "Batch 72\n",
      "Batch 73\n",
      "Batch 74\n",
      "Batch 75\n",
      "Batch 76\n",
      "Batch 77\n",
      "Batch 78\n",
      "Batch 79\n",
      "Batch 80\n",
      "Batch 81\n",
      "Batch 82\n",
      "Batch 83\n",
      "Batch 84\n",
      "Batch 85\n",
      "Batch 86\n",
      "Batch 87\n",
      "Batch 88\n",
      "Batch 89\n",
      "Batch 90\n",
      "Batch 91\n",
      "Batch 92\n",
      "Batch 93\n",
      "Batch 94\n",
      "Batch 95\n",
      "Batch 96\n",
      "Batch 97\n",
      "Batch 98\n",
      "train Loss: 0.1724 Acc: 0.9342\n",
      "Batch 1\n",
      "Batch 2\n",
      "Batch 3\n",
      "Batch 4\n",
      "Batch 5\n",
      "Batch 6\n",
      "Batch 7\n",
      "Batch 8\n",
      "Batch 9\n",
      "Batch 10\n",
      "Batch 11\n",
      "Batch 12\n",
      "Batch 13\n",
      "Batch 14\n",
      "Batch 15\n",
      "Batch 16\n",
      "Batch 17\n",
      "Batch 18\n",
      "Batch 19\n",
      "Batch 20\n",
      "Batch 21\n",
      "Batch 22\n",
      "Batch 23\n",
      "Batch 24\n",
      "Batch 25\n",
      "Batch 26\n",
      "Batch 27\n",
      "Batch 28\n",
      "Batch 29\n",
      "Batch 30\n",
      "Batch 31\n",
      "Batch 32\n",
      "Batch 33\n",
      "val Loss: 0.3408 Acc: 0.8947\n",
      "Epoch 1/2\n",
      "----------\n",
      "Batch 1\n",
      "Batch 2\n",
      "Batch 3\n",
      "Batch 4\n",
      "Batch 5\n",
      "Batch 6\n",
      "Batch 7\n",
      "Batch 8\n",
      "Batch 9\n",
      "Batch 10\n",
      "Batch 11\n",
      "Batch 12\n",
      "Batch 13\n",
      "Batch 14\n",
      "Batch 15\n",
      "Batch 16\n",
      "Batch 17\n",
      "Batch 18\n",
      "Batch 19\n",
      "Batch 20\n",
      "Batch 21\n",
      "Batch 22\n",
      "Batch 23\n",
      "Batch 24\n",
      "Batch 25\n",
      "Batch 26\n",
      "Batch 27\n",
      "Batch 28\n",
      "Batch 29\n",
      "Batch 30\n",
      "Batch 31\n",
      "Batch 32\n",
      "Batch 33\n",
      "Batch 34\n",
      "Batch 35\n",
      "Batch 36\n",
      "Batch 37\n",
      "Batch 38\n",
      "Batch 39\n",
      "Batch 40\n",
      "Batch 41\n",
      "Batch 42\n",
      "Batch 43\n",
      "Batch 44\n",
      "Batch 45\n",
      "Batch 46\n",
      "Batch 47\n",
      "Batch 48\n",
      "Batch 49\n",
      "Batch 50\n",
      "Batch 51\n",
      "Batch 52\n",
      "Batch 53\n",
      "Batch 54\n",
      "Batch 55\n",
      "Batch 56\n",
      "Batch 57\n",
      "Batch 58\n",
      "Batch 59\n",
      "Batch 60\n",
      "Batch 61\n",
      "Batch 62\n",
      "Batch 63\n",
      "Batch 64\n",
      "Batch 65\n",
      "Batch 66\n",
      "Batch 67\n",
      "Batch 68\n",
      "Batch 69\n",
      "Batch 70\n",
      "Batch 71\n",
      "Batch 72\n",
      "Batch 73\n",
      "Batch 74\n",
      "Batch 75\n",
      "Batch 76\n",
      "Batch 77\n",
      "Batch 78\n",
      "Batch 79\n",
      "Batch 80\n",
      "Batch 81\n",
      "Batch 82\n",
      "Batch 83\n",
      "Batch 84\n",
      "Batch 85\n",
      "Batch 86\n",
      "Batch 87\n",
      "Batch 88\n",
      "Batch 89\n",
      "Batch 90\n",
      "Batch 91\n",
      "Batch 92\n",
      "Batch 93\n",
      "Batch 94\n",
      "Batch 95\n",
      "Batch 96\n",
      "Batch 97\n",
      "Batch 98\n",
      "train Loss: 0.1597 Acc: 0.9488\n",
      "Batch 1\n",
      "Batch 2\n",
      "Batch 3\n",
      "Batch 4\n",
      "Batch 5\n",
      "Batch 6\n",
      "Batch 7\n",
      "Batch 8\n",
      "Batch 9\n",
      "Batch 10\n",
      "Batch 11\n",
      "Batch 12\n",
      "Batch 13\n",
      "Batch 14\n",
      "Batch 15\n",
      "Batch 16\n",
      "Batch 17\n",
      "Batch 18\n",
      "Batch 19\n",
      "Batch 20\n",
      "Batch 21\n",
      "Batch 22\n",
      "Batch 23\n",
      "Batch 24\n",
      "Batch 25\n",
      "Batch 26\n",
      "Batch 27\n",
      "Batch 28\n",
      "Batch 29\n",
      "Batch 30\n",
      "Batch 31\n",
      "Batch 32\n",
      "Batch 33\n",
      "val Loss: 0.3437 Acc: 0.8947\n",
      "Epoch 2/2\n",
      "----------\n",
      "Batch 1\n",
      "Batch 2\n",
      "Batch 3\n",
      "Batch 4\n",
      "Batch 5\n",
      "Batch 6\n",
      "Batch 7\n",
      "Batch 8\n",
      "Batch 9\n",
      "Batch 10\n",
      "Batch 11\n",
      "Batch 12\n",
      "Batch 13\n",
      "Batch 14\n",
      "Batch 15\n",
      "Batch 16\n",
      "Batch 17\n",
      "Batch 18\n",
      "Batch 19\n",
      "Batch 20\n",
      "Batch 21\n",
      "Batch 22\n",
      "Batch 23\n",
      "Batch 24\n",
      "Batch 25\n",
      "Batch 26\n",
      "Batch 27\n",
      "Batch 28\n",
      "Batch 29\n",
      "Batch 30\n",
      "Batch 31\n",
      "Batch 32\n",
      "Batch 33\n",
      "Batch 34\n",
      "Batch 35\n",
      "Batch 36\n",
      "Batch 37\n",
      "Batch 38\n",
      "Batch 39\n",
      "Batch 40\n",
      "Batch 41\n",
      "Batch 42\n",
      "Batch 43\n",
      "Batch 44\n",
      "Batch 45\n",
      "Batch 46\n",
      "Batch 47\n",
      "Batch 48\n",
      "Batch 49\n",
      "Batch 50\n",
      "Batch 51\n",
      "Batch 52\n",
      "Batch 53\n",
      "Batch 54\n",
      "Batch 55\n",
      "Batch 56\n",
      "Batch 57\n",
      "Batch 58\n",
      "Batch 59\n",
      "Batch 60\n",
      "Batch 61\n",
      "Batch 62\n",
      "Batch 63\n",
      "Batch 64\n",
      "Batch 65\n",
      "Batch 66\n",
      "Batch 67\n",
      "Batch 68\n",
      "Batch 69\n",
      "Batch 70\n",
      "Batch 71\n",
      "Batch 72\n",
      "Batch 73\n",
      "Batch 74\n",
      "Batch 75\n",
      "Batch 76\n",
      "Batch 77\n",
      "Batch 78\n",
      "Batch 79\n",
      "Batch 80\n",
      "Batch 81\n",
      "Batch 82\n",
      "Batch 83\n",
      "Batch 84\n",
      "Batch 85\n",
      "Batch 86\n",
      "Batch 87\n",
      "Batch 88\n",
      "Batch 89\n",
      "Batch 90\n",
      "Batch 91\n",
      "Batch 92\n",
      "Batch 93\n",
      "Batch 94\n",
      "Batch 95\n",
      "Batch 96\n",
      "Batch 97\n",
      "Batch 98\n",
      "train Loss: 0.1747 Acc: 0.9371\n",
      "Batch 1\n",
      "Batch 2\n",
      "Batch 3\n",
      "Batch 4\n",
      "Batch 5\n",
      "Batch 6\n",
      "Batch 7\n",
      "Batch 8\n",
      "Batch 9\n",
      "Batch 10\n",
      "Batch 11\n",
      "Batch 12\n",
      "Batch 13\n",
      "Batch 14\n",
      "Batch 15\n",
      "Batch 16\n",
      "Batch 17\n",
      "Batch 18\n",
      "Batch 19\n",
      "Batch 20\n",
      "Batch 21\n",
      "Batch 22\n",
      "Batch 23\n",
      "Batch 24\n",
      "Batch 25\n",
      "Batch 26\n",
      "Batch 27\n",
      "Batch 28\n",
      "Batch 29\n",
      "Batch 30\n",
      "Batch 31\n",
      "Batch 32\n",
      "Batch 33\n",
      "val Loss: 0.3451 Acc: 0.8882\n",
      "Training complete in 3m 53s\n",
      "Best val Acc: 0.894737\n"
     ]
    }
   ],
   "source": [
    "lr = 0.00001\n",
    "optim = optim = optimize.SGD(modelTest.parameters(), lr=lr, momentum=momentum, weight_decay=regL2_mult)\n",
    "modelTest, historyThree = train_model(modelTest, {\"train\": train_dataloader, \"val\": test_dataloader}, criterion, optim, 3, 0)\n",
    "history.append(historyThree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0, 2, 2, 0, 2, 2, 0, 0, 2, 0, 2, 0, 2, 2, 0, 2, 2, 0, 0, 2, 2, 0, 0, 0, 2, 0, 2, 2, 0, 1, 2, 2, 2, 2, 0, 2, 0, 2, 0, 0, 0, 2, 0, 2, 1, 2, 0, 0, 2, 0, 0, 0, 2, 2, 0, 2, 2, 2, 0, 0, 2, 2, 0, 2, 0, 2, 2, 0, 0, 2, 2, 0, 0, 2, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 0, 2, 0, 2, 2, 2, 2, 2, 0, 2, 0, 0, 0, 1, 2, 2, 2, 0, 2, 0, 2, 0, 2, 0, 2, 2, 0, 0, 2, 2, 1, 2, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 0, 2, 0, 2, 2, 0, 0, 0, 2, 2, 2, 2, 0, 2, 0, 0, 0, 2, 0, 2, 0, 2, 2, 2, 2, 2, 0, 0, 2, 2, 1, 2, 0, 0, 0, 0, 2, 0, 2, 2, 0, 0, 0, 0, 0, 2, 2, 0, 0, 1, 2, 0, 2, 2, 1, 2, 2, 2, 2, 1, 0, 2, 2, 1, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 1, 2, 2, 2, 2, 0, 2, 0, 0, 2, 0, 0, 2, 2, 0, 0, 0, 2, 2, 1, 2, 0, 0, 2, 2, 0, 2, 2, 2, 0, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 0, 2, 2, 0, 0, 0, 0, 0, 2, 0, 2, 2, 1, 2, 0, 2, 1, 2, 0, 1, 2, 0, 2, 2, 2, 0, 0, 0, 0, 2, 2, 2, 0, 1, 1, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 1, 0, 0, 0, 1, 2, 0, 2, 0, 2, 2, 2, 0, 2, 2, 0, 0, 0, 0, 2, 2, 0, 2, 2, 2, 0, 1, 2, 1, 0, 0, 2, 0, 0, 0, 2, 0, 0, 2, 0, 2, 0, 2, 2, 0, 0, 0, 2, 2, 0, 0, 2, 0, 2, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 2, 2, 1, 2, 2, 2, 0, 2, 2, 0, 2, 0, 0, 1, 0, 0, 0, 2, 0, 2, 2, 0, 2, 2, 0, 0, 2, 2, 0, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 2, 0, 2, 2, 1, 0, 0, 0, 2, 0, 0, 0, 0, 2, 1, 0, 2, 0, 2, 2, 0, 0, 2, 1, 2, 2, 2, 2, 0, 2, 2, 2, 0, 0, 2, 2, 0, 0, 0, 2, 2, 2, 1]\n[0, 2, 2, 2, 2, 2, 0, 0, 2, 0, 2, 0, 2, 2, 0, 2, 2, 0, 0, 2, 2, 0, 0, 0, 2, 0, 2, 2, 0, 0, 2, 2, 2, 2, 0, 2, 0, 2, 0, 0, 0, 2, 0, 2, 2, 2, 0, 1, 2, 2, 0, 0, 2, 0, 0, 2, 2, 2, 0, 0, 2, 2, 0, 2, 0, 2, 2, 0, 0, 0, 2, 0, 0, 2, 2, 0, 2, 1, 2, 2, 0, 2, 2, 2, 0, 2, 0, 0, 2, 2, 2, 0, 0, 2, 0, 0, 0, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 0, 2, 2, 0, 0, 2, 2, 0, 2, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 0, 2, 2, 0, 2, 0, 2, 2, 2, 2, 0, 2, 0, 0, 0, 2, 0, 2, 0, 2, 2, 2, 0, 2, 0, 0, 2, 2, 0, 2, 0, 0, 0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 2, 0, 2, 0, 2, 2, 2, 2, 2, 1, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 0, 0, 2, 2, 0, 0, 0, 2, 2, 2, 2, 0, 0, 2, 2, 0, 2, 2, 2, 0, 2, 2, 2, 2, 0, 2, 1, 2, 2, 2, 0, 2, 2, 0, 0, 1, 0, 0, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 0, 1, 2, 0, 0, 2, 2, 0, 0, 0, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 0, 2, 2, 0, 2, 0, 2, 2, 2, 0, 2, 2, 0, 0, 0, 0, 2, 2, 0, 2, 2, 2, 0, 1, 2, 2, 0, 0, 2, 0, 0, 2, 2, 0, 0, 2, 0, 2, 0, 2, 2, 0, 0, 0, 2, 2, 0, 0, 2, 0, 2, 0, 0, 0, 2, 2, 0, 2, 2, 2, 2, 2, 0, 2, 0, 2, 0, 0, 2, 2, 0, 2, 2, 2, 2, 0, 2, 0, 2, 2, 0, 0, 0, 0, 0, 2, 0, 2, 2, 0, 2, 2, 0, 0, 2, 2, 0, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 2, 0, 2, 0, 2, 0, 0, 2, 2, 0, 0, 0, 0, 2, 0, 0, 2, 0, 2, 2, 0, 0, 2, 2, 2, 2, 2, 1, 0, 2, 2, 2, 2, 0, 2, 2, 0, 0, 0, 2, 2, 2, 0]\n              precision    recall  f1-score   support\n\n        none       0.90      0.90      0.90       183\n        mild       0.38      0.11      0.17        27\n      severe       0.89      0.95      0.92       246\n\n    accuracy                           0.88       456\n   macro avg       0.72      0.65      0.66       456\nweighted avg       0.86      0.88      0.87       456\n\n"
     ]
    }
   ],
   "source": [
    "results = doValidation(modelTest, dev_dataloader)\n",
    "targetNames = ['none', 'mild', 'severe']\n",
    "print(results['real'])\n",
    "print(results['pred'])\n",
    "print(classification_report(results['real'], results['pred'], target_names=targetNames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}